version: '3.8'

services:
  deepseek-llm:
    image: ghcr.io/huggingface/text-generation-inference:3.3.4
    container_name: deepseek-llm
    ports:
      - "8080:80"  # API будет доступен на localhost:8080
    environment:
      - MODEL_ID=deepseek-ai/deepseek-llm-7b  # или другая версия
      - QUANTIZE=bitsandbytes  # (опционально) для оптимизации
      - MAX_INPUT_LENGTH=4096
    volumes:
      - ./data:/data
    command: --model-id ${MODEL_ID} --quantize ${QUANTIZE} --max-input-length ${MAX_INPUT_LENGTH}
